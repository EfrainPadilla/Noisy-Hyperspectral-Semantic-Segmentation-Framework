WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1178s vs `on_train_batch_end` time: 0.4109s). Check your callbacks.
2021-07-14 01:41:36.722484
SNR= 45dB
Alpha= alpha-1.0
---The HSI selected is: paviaU ---
The shape of the image is: (610, 340, 103)
The shape of the labels is: (610, 340)
Number of classes:  9
Standard Scaler preprocessing method applied
The new shape of the data is:  (207400, 19, 19, 103)
The new shape of the labels is:  (207400,)
The data shape for train is: (427, 19, 19, 103)
The labels shape for train is: (427,)
The data shape for test is: (42349, 19, 19, 103)
The labels shape for test is: (42349,)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d (Conv3D)              (None, 15, 15, 80, 32)    19232     
_________________________________________________________________
batch_normalization (BatchNo (None, 15, 15, 80, 32)    128       
_________________________________________________________________
activation (Activation)      (None, 15, 15, 80, 32)    0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 11, 11, 65, 64)    819264    
_________________________________________________________________
batch_normalization_1 (Batch (None, 11, 11, 65, 64)    256       
_________________________________________________________________
activation_1 (Activation)    (None, 11, 11, 65, 64)    0         
_________________________________________________________________
max_pooling3d (MaxPooling3D) (None, 5, 5, 65, 64)      0         
_________________________________________________________________
flatten (Flatten)            (None, 104000)            0         
_________________________________________________________________
dense (Dense)                (None, 300)               31200300  
_________________________________________________________________
batch_normalization_2 (Batch (None, 300)               1200      
_________________________________________________________________
activation_2 (Activation)    (None, 300)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 9)                 2709      
=================================================================
Total params: 32,043,089
Trainable params: 32,042,297
Non-trainable params: 792
_________________________________________________________________
Epoch 1/40

Epoch 00001: val_accuracy improved from -inf to 0.18858, saving model to /tmp/best_model.h5
Epoch 2/40

Epoch 00002: val_accuracy improved from 0.18858 to 0.22518, saving model to /tmp/best_model.h5
Epoch 3/40

Epoch 00003: val_accuracy did not improve from 0.22518
Epoch 4/40

Epoch 00004: val_accuracy improved from 0.22518 to 0.22782, saving model to /tmp/best_model.h5
Epoch 5/40

Epoch 00005: val_accuracy improved from 0.22782 to 0.27535, saving model to /tmp/best_model.h5
Epoch 6/40

Epoch 00006: val_accuracy improved from 0.27535 to 0.35255, saving model to /tmp/best_model.h5
Epoch 7/40

Epoch 00007: val_accuracy improved from 0.35255 to 0.38480, saving model to /tmp/best_model.h5
Epoch 8/40

Epoch 00008: val_accuracy improved from 0.38480 to 0.40164, saving model to /tmp/best_model.h5
Epoch 9/40

Epoch 00009: val_accuracy improved from 0.40164 to 0.41871, saving model to /tmp/best_model.h5
Epoch 10/40

Epoch 00010: val_accuracy improved from 0.41871 to 0.45347, saving model to /tmp/best_model.h5
Epoch 11/40

Epoch 00011: val_accuracy improved from 0.45347 to 0.45921, saving model to /tmp/best_model.h5
Epoch 12/40

Epoch 00012: val_accuracy improved from 0.45921 to 0.48632, saving model to /tmp/best_model.h5
Epoch 13/40

Epoch 00013: val_accuracy improved from 0.48632 to 0.49996, saving model to /tmp/best_model.h5
Epoch 14/40

Epoch 00014: val_accuracy improved from 0.49996 to 0.52622, saving model to /tmp/best_model.h5
Epoch 15/40

Epoch 00015: val_accuracy improved from 0.52622 to 0.55319, saving model to /tmp/best_model.h5
Epoch 16/40

Epoch 00016: val_accuracy improved from 0.55319 to 0.55933, saving model to /tmp/best_model.h5
Epoch 17/40

Epoch 00017: val_accuracy improved from 0.55933 to 0.58306, saving model to /tmp/best_model.h5
Epoch 18/40

Epoch 00018: val_accuracy improved from 0.58306 to 0.60615, saving model to /tmp/best_model.h5
Epoch 19/40

Epoch 00019: val_accuracy improved from 0.60615 to 0.65336, saving model to /tmp/best_model.h5
Epoch 20/40

Epoch 00020: val_accuracy improved from 0.65336 to 0.68188, saving model to /tmp/best_model.h5
Epoch 21/40

Epoch 00021: val_accuracy improved from 0.68188 to 0.68965, saving model to /tmp/best_model.h5
Epoch 22/40

Epoch 00022: val_accuracy improved from 0.68965 to 0.69997, saving model to /tmp/best_model.h5
Epoch 23/40

Epoch 00023: val_accuracy improved from 0.69997 to 0.75657, saving model to /tmp/best_model.h5
Epoch 24/40

Epoch 00024: val_accuracy improved from 0.75657 to 0.80533, saving model to /tmp/best_model.h5
Epoch 25/40

Epoch 00025: val_accuracy improved from 0.80533 to 0.80802, saving model to /tmp/best_model.h5
Epoch 26/40

Epoch 00026: val_accuracy improved from 0.80802 to 0.81426, saving model to /tmp/best_model.h5
Epoch 27/40

Epoch 00027: val_accuracy improved from 0.81426 to 0.83067, saving model to /tmp/best_model.h5
Epoch 28/40

Epoch 00028: val_accuracy improved from 0.83067 to 0.83074, saving model to /tmp/best_model.h5
Epoch 29/40

Epoch 00029: val_accuracy improved from 0.83074 to 0.83797, saving model to /tmp/best_model.h5
Epoch 30/40

Epoch 00030: val_accuracy did not improve from 0.83797
Epoch 31/40

Epoch 00031: val_accuracy improved from 0.83797 to 0.87159, saving model to /tmp/best_model.h5
Epoch 32/40

Epoch 00032: val_accuracy improved from 0.87159 to 0.88647, saving model to /tmp/best_model.h5
Epoch 33/40

Epoch 00033: val_accuracy did not improve from 0.88647
Epoch 34/40

Epoch 00034: val_accuracy did not improve from 0.88647
Epoch 35/40

Epoch 00035: val_accuracy improved from 0.88647 to 0.89851, saving model to /tmp/best_model.h5
Epoch 36/40

Epoch 00036: val_accuracy did not improve from 0.89851
Epoch 37/40

Epoch 00037: val_accuracy did not improve from 0.89851
Epoch 38/40

Epoch 00038: val_accuracy improved from 0.89851 to 0.91355, saving model to /tmp/best_model.h5
Epoch 39/40

Epoch 00039: val_accuracy did not improve from 0.91355
Epoch 40/40

Epoch 00040: val_accuracy did not improve from 0.91355
PARAMETERS 32043089

Terminado en 2059.203134536743 segundos!


Classification report:
              precision    recall  f1-score   support

           0       0.92      0.92      0.92      6565
           1       0.96      0.98      0.97     18463
           2       0.57      0.84      0.68      2078
           3       0.86      0.99      0.92      3033
           4       0.94      1.00      0.97      1332
           5       0.96      0.83      0.89      4979
           6       0.92      0.60      0.73      1317
           7       0.91      0.72      0.80      3645
           8       0.92      0.99      0.95       937

    accuracy                           0.91     42349
   macro avg       0.88      0.87      0.87     42349
weighted avg       0.92      0.91      0.91     42349

Accuracy Score: 0.9135516777255661
Accuracy by each class: [0.916 0.981 0.839 0.992 1.    0.827 0.604 0.721 0.993]
Average accuracy 0.8747771987852704
Cohenâ€™s kappa score:  0.8852388694141238
