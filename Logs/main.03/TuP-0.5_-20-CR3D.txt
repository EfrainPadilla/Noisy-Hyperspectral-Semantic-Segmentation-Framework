2021-07-28 08:22:22.843033
SNR= -20dB
Alpha= alpha-0.5
---The HSI selected is: paviaU ---
The shape of the image is: (610, 340, 103)
The shape of the labels is: (610, 340)
Number of classes:  9
Standard Scaler preprocessing method applied
The new dimensions for the compressed HSI is: (610, 340, 40) obtained by Tucker
The new shape of the data is:  (207400, 19, 19, 40)
The new shape of the labels is:  (207400,)
The data shape for train is: (1283, 19, 19, 40)
The labels shape for train is: (1283,)
The data shape for test is: (41493, 19, 19, 40)
The labels shape for test is: (41493,)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d (Conv3D)              (None, 15, 15, 17, 32)    19232     
_________________________________________________________________
batch_normalization (BatchNo (None, 15, 15, 17, 32)    128       
_________________________________________________________________
activation (Activation)      (None, 15, 15, 17, 32)    0         
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 11, 11, 2, 64)     819264    
_________________________________________________________________
batch_normalization_1 (Batch (None, 11, 11, 2, 64)     256       
_________________________________________________________________
activation_1 (Activation)    (None, 11, 11, 2, 64)     0         
_________________________________________________________________
max_pooling3d (MaxPooling3D) (None, 5, 5, 2, 64)       0         
_________________________________________________________________
flatten (Flatten)            (None, 3200)              0         
_________________________________________________________________
dense (Dense)                (None, 300)               960300    
_________________________________________________________________
batch_normalization_2 (Batch (None, 300)               1200      
_________________________________________________________________
activation_2 (Activation)    (None, 300)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 9)                 2709      
=================================================================
Total params: 1,803,089
Trainable params: 1,802,297
Non-trainable params: 792
_________________________________________________________________
Epoch 1/40

Epoch 00001: val_accuracy improved from -inf to 0.13523, saving model to /tmp/best_model.h5
Epoch 2/40

Epoch 00002: val_accuracy improved from 0.13523 to 0.26551, saving model to /tmp/best_model.h5
Epoch 3/40

Epoch 00003: val_accuracy improved from 0.26551 to 0.73892, saving model to /tmp/best_model.h5
Epoch 4/40

Epoch 00004: val_accuracy did not improve from 0.73892
Epoch 5/40

Epoch 00005: val_accuracy did not improve from 0.73892
Epoch 6/40

Epoch 00006: val_accuracy did not improve from 0.73892
Epoch 7/40

Epoch 00007: val_accuracy did not improve from 0.73892
Epoch 8/40

Epoch 00008: val_accuracy did not improve from 0.73892
Epoch 9/40

Epoch 00009: val_accuracy did not improve from 0.73892
Epoch 10/40

Epoch 00010: val_accuracy did not improve from 0.73892
Epoch 11/40

Epoch 00011: val_accuracy did not improve from 0.73892
Epoch 12/40

Epoch 00012: val_accuracy did not improve from 0.73892
Epoch 13/40

Epoch 00013: val_accuracy did not improve from 0.73892
Epoch 14/40

Epoch 00014: val_accuracy did not improve from 0.73892
Epoch 15/40

Epoch 00015: val_accuracy did not improve from 0.73892
Epoch 16/40

Epoch 00016: val_accuracy did not improve from 0.73892
Epoch 17/40

Epoch 00017: val_accuracy did not improve from 0.73892
Epoch 18/40

Epoch 00018: val_accuracy did not improve from 0.73892
Epoch 19/40

Epoch 00019: val_accuracy did not improve from 0.73892
Epoch 20/40

Epoch 00020: val_accuracy did not improve from 0.73892
Epoch 21/40

Epoch 00021: val_accuracy did not improve from 0.73892
Epoch 22/40

Epoch 00022: val_accuracy improved from 0.73892 to 0.74369, saving model to /tmp/best_model.h5
Epoch 23/40

Epoch 00023: val_accuracy improved from 0.74369 to 0.75427, saving model to /tmp/best_model.h5
Epoch 24/40

Epoch 00024: val_accuracy improved from 0.75427 to 0.76738, saving model to /tmp/best_model.h5
Epoch 25/40

Epoch 00025: val_accuracy improved from 0.76738 to 0.77678, saving model to /tmp/best_model.h5
Epoch 26/40

Epoch 00026: val_accuracy improved from 0.77678 to 0.78852, saving model to /tmp/best_model.h5
Epoch 27/40

Epoch 00027: val_accuracy improved from 0.78852 to 0.80724, saving model to /tmp/best_model.h5
Epoch 28/40

Epoch 00028: val_accuracy improved from 0.80724 to 0.81845, saving model to /tmp/best_model.h5
Epoch 29/40

Epoch 00029: val_accuracy improved from 0.81845 to 0.82604, saving model to /tmp/best_model.h5
Epoch 30/40

Epoch 00030: val_accuracy improved from 0.82604 to 0.83277, saving model to /tmp/best_model.h5
Epoch 31/40

Epoch 00031: val_accuracy improved from 0.83277 to 0.83754, saving model to /tmp/best_model.h5
Epoch 32/40

Epoch 00032: val_accuracy improved from 0.83754 to 0.84609, saving model to /tmp/best_model.h5
Epoch 33/40

Epoch 00033: val_accuracy improved from 0.84609 to 0.85137, saving model to /tmp/best_model.h5
Epoch 34/40

Epoch 00034: val_accuracy improved from 0.85137 to 0.85672, saving model to /tmp/best_model.h5
Epoch 35/40

Epoch 00035: val_accuracy improved from 0.85672 to 0.86080, saving model to /tmp/best_model.h5
Epoch 36/40

Epoch 00036: val_accuracy improved from 0.86080 to 0.86651, saving model to /tmp/best_model.h5
Epoch 37/40

Epoch 00037: val_accuracy improved from 0.86651 to 0.86916, saving model to /tmp/best_model.h5
Epoch 38/40

Epoch 00038: val_accuracy improved from 0.86916 to 0.87441, saving model to /tmp/best_model.h5
Epoch 39/40

Epoch 00039: val_accuracy improved from 0.87441 to 0.87494, saving model to /tmp/best_model.h5
Epoch 40/40

Epoch 00040: val_accuracy improved from 0.87494 to 0.87622, saving model to /tmp/best_model.h5
PARAMETERS 1803089

Terminado en 217.76105570793152 segundos!


Classification report:
              precision    recall  f1-score   support

           0       0.72      0.98      0.83      6432
           1       0.92      0.99      0.95     18090
           2       0.80      0.43      0.56      2036
           3       0.98      0.93      0.96      2972
           4       1.00      1.00      1.00      1305
           5       0.92      0.71      0.80      4878
           6       0.78      0.19      0.31      1290
           7       0.88      0.73      0.80      3571
           8       0.98      0.98      0.98       919

    accuracy                           0.88     41493
   macro avg       0.89      0.77      0.80     41493
weighted avg       0.88      0.88      0.86     41493

Accuracy Score: 0.8762200853155954
Accuracy by each class: [0.978 0.99  0.429 0.932 0.997 0.708 0.19  0.732 0.977]
Average accuracy 0.7703314432429376
Cohenâ€™s kappa score:  0.8321234344806586
