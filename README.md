# Noisy-Hyperspectral-Semantic-Segmentation-Framework
Code of the Publication "A Semantic Segmentation Framework for Hyperspectral Imagery Based on Tucker Decomposition and 3DCNN Tested with Simulated Noisy Scenarios"
Already published on: https://doi.org/10.3390/rs15051399

Authors: Efrain Padilla-Zepeda, Deni Torres-Roman, Andres Mendez-Vazquez

The implementation of Deep Learning Models is based on the code of @mhaut https://github.com/mhaut/hyperspectral_deeplearning_review

The Tucker decomposition is a modification of a the Tensorly implementation of this algorithm. http://tensorly.org/stable/index.html

VBMF (Variational Bayes Matrix Factorization) script is not used for the content of the paper, but it is included for future work, used for rank-3 selection for Tucker decomposition.
