# Noisy-Hyperspectral-Semantic-Segmentation-Framework
Code of the Publication "A Semantic Segmentation Framework based on Tucker Decomposition and Deep Learning for Noisy Scenarios of Hyperspectral Imagery" (Will be published soon)

The implementation of Deep Learning Models is based on the code of @mhaut https://github.com/mhaut/hyperspectral_deeplearning_review
The Tucker decomposition is a modification of a the Tensorly implementation of this algorithm. http://tensorly.org/stable/index.html
